{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: Study the various Recommendation Techniques for recommending movies using\n",
    "movies.csv, ratings.csv datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.decomposition import TruncatedSVD, NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load movies.csv and ratings.csv dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = pd.read_csv('movies.csv')\n",
    "ratings_df = pd.read_csv('ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.info()\n",
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df.info()\n",
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge both data frames on movieid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(ratings_df, movies_df, on='movieId')\n",
    "df.head()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combined dataframe is 100836 rows and 6 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genres of Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = {}\n",
    "\n",
    "def find_genres():\n",
    "    for genre in df['genres']:\n",
    "        words = genre.split('|')\n",
    "        for word in words:\n",
    "            genres[word] = genres.get(word, 0) + 1\n",
    "find_genres()\n",
    "\n",
    "# replace '(no genres listed)' by 'None'\n",
    "genres['None'] = genres.pop('(no genres listed)')\n",
    "\n",
    "genres_df = pd.DataFrame(list(genres.items()), columns=['genres', 'count'])\n",
    "genres_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20 total Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-v0_8')\n",
    "sns.barplot(x=genres_df['genres'], y=genres_df['count'])\n",
    "plt.title('Bar plot of Movie Genres')\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Movie Genres')\n",
    "plt.ylabel('Number of Movies')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Rated Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings_agg = pd.DataFrame(df.groupby('title')['rating'].mean())\n",
    "df_ratings_agg['total ratings'] = pd.DataFrame(df.groupby('title')['rating'].count())\n",
    "df_ratings_agg.rename(columns={'rating': 'mean rating'}, inplace=True)\n",
    "df_ratings_agg.sort_values('total ratings', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "sns.histplot(df_ratings_agg['total ratings'], bins=20, kde=True)\n",
    "plt.xlabel('Total Number of Ratings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Majority of movies have less that 50 ratings and the top 3 movies have over 300 ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "sns.histplot(df_ratings_agg['mean rating'], bins='auto', kde=True)\n",
    "plt.title('Distribution of Mean Rating')\n",
    "plt.xlabel('Mean Rating')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create User-Item Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_matrix = pd.pivot_table(df, index='userId', columns='title', values='rating')\n",
    "print(user_item_matrix.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform User-based Collaborative Filtering\n",
    "\n",
    "### Fill the row-wise NaNs in the User-Item Matrix with the corresponding user's mean ratings, and find the Pearson correlation between users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values with user mean ratings\n",
    "user_item_matrix_filled = user_item_matrix.T.fillna(user_item_matrix.T.mean()).T\n",
    "\n",
    "# Display the matrix after filling NaNs\n",
    "print(user_item_matrix_filled.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the correlation of all users with only User 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Pearson correlation matrix\n",
    "user_item_matrix_filled.T.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User 1 correlation to other users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user1_corr = user_item_matrix_filled.T.corr()[1].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sort the User 1 correlation in the descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user1_corr.sort_values(ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop the NaN values generated in the correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user1_corr.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the top 50 users that are highly correlated to User 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_50_corr_users = user1_corr[1:51]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of Movie ID 32\n",
    "movies_df['title'][movies_df['movieId']==32].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Movies Rated by User 1\n",
    "print(df[df['userId']==1])\n",
    "\n",
    "# Users that rated Twelve Monkeys\n",
    "print(df[df['movieId']== 32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen, User 1 has not seen Twelve Monkeys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the rating that User 1 might give for the movie with movieid 32 based on the top 50 user correlation matrix\n",
    "(Hint: Predicted rating = sum of [(weights) * (ratings)] / sum of (weights ). Here, weights is the correlation of the corresponding user with the first user). That is, the predicted ratingis calculated as the weighted average of k similar users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 1: Predicting using only users that rated Movie 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twelve Monkeys mean rating and total ratings\n",
    "df_ratings_agg.loc[['Twelve Monkeys (a.k.a. 12 Monkeys) (1995)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_50_users = top_50_corr_users.keys()\n",
    "\n",
    "count = 0\n",
    "users = list() \n",
    "for user in top_50_users:\n",
    "    # Filter each user in top 50 that rated movie 32\n",
    "    if df[(df['userId']==user) & (df['movieId']==32)]['rating'].sum():\n",
    "        count += 1\n",
    "        users.append(user)\n",
    "print(f'Total users that rated Twelve Monkeys: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rating():\n",
    "    sum_similarity = 0\n",
    "    weighted_ratings = 0\n",
    "    for user in users:\n",
    "        weighted_ratings += top_50_corr_users.loc[user] * df[(df['userId']==user) & (df['movieId']==32)]['rating'].sum()\n",
    "        sum_similarity += top_50_corr_users.loc[user]\n",
    "\n",
    "    return(weighted_ratings/sum_similarity)\n",
    "print(f'Predicted User 1 rating for Twelve Monkeys {predict_rating()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 2 if filled with NaNs filled with user means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_top_50_users = user_item_matrix_filled.loc[top_50_corr_users.index,'Twelve Monkeys (a.k.a. 12 Monkeys) (1995)']\n",
    "weights = top_50_users.values\n",
    "weighted_sum = (ratings_top_50_users * weights).sum()\n",
    "weights_sum = weights.sum()\n",
    "predicted_rating = weighted_sum / weights_sum\n",
    "print(\"Predicted User 1 rating with filled means for Twelve Monkeys: \", predicted_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Item-based Collaborative Filtering\n",
    "### Fill the column-wise NaN's in the User-Item Matrix with the corresponding movie's mean ratings, and find Pearson correlation between movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_item_filled = user_item_matrix.apply(lambda col: col.fillna(col.mean()), axis=0)\n",
    "\n",
    "movie_corr = movie_item_filled.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the correlation of all movies with the movie Jurassic Park (1993) only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jurassic_corr = movie_corr[\"Jurassic Park (1993)\"].dropna().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort the Jurassic Park movie correlation in descending order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find 10 movies similar to the movie Jurassic Park (1993)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_movies = jurassic_corr.drop(labels=[\"Jurassic Park (1993)\"]).head(10)\n",
    "print(\"\\nTop 10 movies similar to 'Jurassic Park (1993)':\")\n",
    "print(similar_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform KNNBasic, SVD, NMF Model-based Collaborative Filtering\n",
    "Initialize KNNBasic with similarity configuration as Mean Squared Distance Similarity (msd), 20 neighbors and cross-validate 5 folds against measure RMSE.\n",
    "(Hint: cross_validate(algo=algo, data=data, measures=['RMSE'], cv=5, verbose=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/cullen/Documents/Python-Projects/.venv/lib/python3.9/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/cullen/Documents/Python-Projects/.venv/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/cullen/Documents/Python-Projects/.venv/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/cullen/Documents/Python-Projects/.venv/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/cullen/Documents/Python-Projects/.venv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/cullen/Documents/Python-Projects/.venv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/cullen/Documents/Python-Projects/.venv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/cullen/Documents/Python-Projects/.venv/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/cullen/Documents/Python-Projects/.venv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/cullen/Documents/Python-Projects/.venv/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/cullen/Documents/Python-Projects/.venv/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/cullen/Documents/Python-Projects/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/cullen/Documents/Python-Projects/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/cullen/Documents/Python-Projects/.venv/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/cullen/Documents/Python-Projects/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/cullen/Documents/Python-Projects/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/cullen/Documents/Python-Projects/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/q9/tcnkwbxn3pv75_gj_6zrz_c80000gn/T/ipykernel_12874/3960920156.py\", line 1, in <module>\n",
      "    from surprise import Reader, Dataset, KNNBasic, SVD, NMF\n",
      "  File \"/Users/cullen/Documents/Python-Projects/.venv/lib/python3.9/site-packages/surprise/__init__.py\", line 6, in <module>\n",
      "    from .prediction_algorithms import (\n",
      "  File \"/Users/cullen/Documents/Python-Projects/.venv/lib/python3.9/site-packages/surprise/prediction_algorithms/__init__.py\", line 23, in <module>\n",
      "    from .algo_base import AlgoBase\n",
      "  File \"/Users/cullen/Documents/Python-Projects/.venv/lib/python3.9/site-packages/surprise/prediction_algorithms/algo_base.py\", line 8, in <module>\n",
      "    from .. import similarities as sims\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import (auto-generated because you didn't call 'numpy.import_array()' after cimporting numpy; use '<void>numpy._import_array' to disable if you are certain you don't need it).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msurprise\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Reader, Dataset, KNNBasic, SVD, NMF\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msurprise\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split, GridSearchCV, cross_validate\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msurprise\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m accuracy\n",
      "File \u001b[0;32m~/Documents/Python-Projects/.venv/lib/python3.9/site-packages/surprise/__init__.py:6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuiltin_datasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_dataset_dir\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprediction_algorithms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      7\u001b[0m     AlgoBase,\n\u001b[1;32m      8\u001b[0m     BaselineOnly,\n\u001b[1;32m      9\u001b[0m     CoClustering,\n\u001b[1;32m     10\u001b[0m     KNNBaseline,\n\u001b[1;32m     11\u001b[0m     KNNBasic,\n\u001b[1;32m     12\u001b[0m     KNNWithMeans,\n\u001b[1;32m     13\u001b[0m     KNNWithZScore,\n\u001b[1;32m     14\u001b[0m     NMF,\n\u001b[1;32m     15\u001b[0m     NormalPredictor,\n\u001b[1;32m     16\u001b[0m     Prediction,\n\u001b[1;32m     17\u001b[0m     PredictionImpossible,\n\u001b[1;32m     18\u001b[0m     SlopeOne,\n\u001b[1;32m     19\u001b[0m     SVD,\n\u001b[1;32m     20\u001b[0m     SVDpp,\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Reader\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Trainset\n",
      "File \u001b[0;32m~/Documents/Python-Projects/.venv/lib/python3.9/site-packages/surprise/prediction_algorithms/__init__.py:23\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mThe :mod:`prediction_algorithms` package includes the prediction algorithms\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mavailable for recommendation.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m    co_clustering.CoClustering\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malgo_base\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AlgoBase\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbaseline_only\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaselineOnly\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mco_clustering\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CoClustering\n",
      "File \u001b[0;32m~/Documents/Python-Projects/.venv/lib/python3.9/site-packages/surprise/prediction_algorithms/algo_base.py:8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mThe :mod:`surprise.prediction_algorithms.algo_base` module defines the base\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mclass :class:`AlgoBase` from which every single prediction algorithm has to\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03minherit.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mheapq\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m similarities \u001b[38;5;28;01mas\u001b[39;00m sims\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimize_baselines\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m baseline_als, baseline_sgd\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpredictions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Prediction, PredictionImpossible\n",
      "File \u001b[0;32m~/Documents/Python-Projects/.venv/lib/python3.9/site-packages/surprise/similarities.pyx:1\u001b[0m, in \u001b[0;36minit surprise.similarities\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: numpy.core.multiarray failed to import (auto-generated because you didn't call 'numpy.import_array()' after cimporting numpy; use '<void>numpy._import_array' to disable if you are certain you don't need it)."
     ]
    }
   ],
   "source": [
    "from surprise import Reader, Dataset, KNNBasic, SVD, NMF\n",
    "from surprise.model_selection import train_test_split, GridSearchCV, cross_validate\n",
    "from surprise import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ratings dataset\n",
    "ratings = pd.read_csv('ratings.csv')  # Adjust the path as necessary\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbours (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNNBasic Model\n",
    "knn_algo = KNNBasic(sim_options={'name': 'msd', 'user_based': True})\n",
    "knn_cv_results = cross_validate(knn_algo, data, measures=['RMSE'], cv=5, verbose=True)\n",
    "knn_best_score = knn_cv_results['test_rmse'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Singular Value Decomposition (SVD) and cross-validate 5 folds against measure RMSE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVD Model\n",
    "svd_algo = SVD()\n",
    "svd_cv_results = cross_validate(svd_algo, data, measures=['RMSE'], cv=5, verbose=True)\n",
    "svd_best_score = svd_cv_results['test_rmse'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Non-Negative Matrix Factorization (NMF) and cross-validate 5 folds against measure RMSE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NMF Model\n",
    "nmf_algo = NMF()\n",
    "nmf_cv_results = cross_validate(nmf_algo, data, measures=['RMSE'], cv=5, verbose=True)\n",
    "nmf_best_score = nmf_cv_results['test_rmse'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print best score and best params from Cross Validate on all the models built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print best scores for each model\n",
    "print(f\"KNNBasic Mean RMSE: {knn_best_score:.4f}\")\n",
    "print(f\"SVD Mean RMSE: {svd_best_score:.4f}\")\n",
    "print(f\"NMF Mean RMSE: {nmf_best_score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
